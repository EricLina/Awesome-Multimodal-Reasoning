# Awesome-Multimodal-Reasoning

**Contributions are most welcome**, if you have any suggestions or improvements, feel free to create an issue or raise a pull request.

## Contents
 - [Benchmark](#Visual-Reasoning-Benchmark)
 - [Supervised Fine-Tuning](#Supervised-Fine-Tuning)
 - [Reinforcement Learining](#Reinforcement-Learining)
 - [SFT + RL](##SFT+RL)


## Multimodal Reasoning Benchmark

## Supervised Fine-Tuning
### Image MLLM
- Virgo: A Preliminary Exploration on Reproducing o1-like MLLM
### Video MLLM

## Reinforcement Learining

### Image MLLM
- [InternLM-XComposer2.5-Reward: A Simple Yet Effective Multi-Modal Reward Model](https://arxiv.org/abs/2501.12368)
- [Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization](https://arxiv.org/abs/2411.10442)
- [MM-RLHF: The Next Step Forward in Multimodal LLM Alignment](https://arxiv.org/abs/2502.10391)

### Video MLLM
- [Temporal Preference Optimization for Long-Form Video Understanding](https://arxiv.org/abs/2501.13919)

## SFT+RL

### Image MLLM
- [Improve Vision Language Model Chain-of-thought Reasoning](https://arxiv.org/pdf/2410.16198)

### Video MLLM
- Tarsier2: Advancing Large Vision-Language Models from Detailed Video Description to Comprehensive Video Understanding
- video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Language Model
